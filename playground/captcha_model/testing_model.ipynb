{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee33035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: keras in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: pillow in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (11.3.0)\n",
      "Requirement already satisfied: numpy in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: rich in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from keras) (14.1.0)\n",
      "Requirement already satisfied: namex in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from keras) (0.17.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from rich->keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/smarth/Developer/productionProjects/ledgers/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763ee0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af549550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction model loaded!\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"captcha_prediction_model.keras\")\n",
    "print(\"Prediction model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e8a26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model expects 20 classes, but only 19 characters found.\n",
      "[INFO] Adding CTC blank token...\n",
      "[INFO] Characters: ['c', '7', 'p', 'm', '6', 'b', 'n', '3', '8', 'y', 'w', 'e', 'x', '4', '5', '2', 'g', 'd', 'f', '']\n",
      "[INFO] Character count: 20, Model output classes: 20\n",
      "[INFO] Max length: 5, Image size: 200x50\n",
      "[INFO] Prediction model loaded successfully!\n",
      "[DEBUG] Model input shape: (None, 200, 50, 1)\n",
      "[DEBUG] Model output shape: (None, 50, 20)\n",
      "==================================================\n",
      "BASIC PREDICTION\n",
      "==================================================\n",
      "[INFO] Processing image: test_captcha.png\n",
      "[DEBUG] Original image size: (310, 60)\n",
      "[DEBUG] Original image mode: RGB\n",
      "[DEBUG] Expected shape: (None, 200, 50, 1)\n",
      "[DEBUG] Expected channels: 1\n",
      "[DEBUG] Preprocessed image shape: (1, 200, 50, 1)\n",
      "[DEBUG] Image value range: [0.000, 0.988]\n",
      "[INFO] Making prediction...\n",
      "[DEBUG] Prediction shape: (1, 50, 20)\n",
      "[DEBUG] Prediction sample: [[6.9475288e-07 2.0918046e-06 1.7906518e-07 5.1070015e-07 2.4167886e-07\n",
      "  4.2985803e-08 2.7748973e-07 2.0843301e-07 5.6973153e-07 1.5583750e-07\n",
      "  1.6884169e-07 2.0708154e-07 3.7759261e-07 3.1127533e-07 6.8026009e-07\n",
      "  4.7597626e-07 5.5536515e-07 5.1121083e-07 5.3465106e-07 9.9999118e-01]\n",
      " [2.7667792e-07 3.9827449e-07 2.3014170e-08 6.2529658e-08 9.6724468e-09\n",
      "  2.0886717e-09 1.9902750e-08 1.1678863e-08 2.4572678e-08 2.1837975e-08\n",
      "  5.1616396e-09 8.6450926e-09 7.1301002e-08 1.2985050e-08 9.4850428e-08\n",
      "  5.6741364e-08 5.7542863e-08 2.3118352e-08 8.2556468e-08 9.9999869e-01]]\n",
      "[DEBUG] Predicted indices: [np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19), np.int64(19)]\n",
      "[RESULT] Predicted CAPTCHA: ''\n",
      "\n",
      "==================================================\n",
      "CONFIDENCE-BASED PREDICTION\n",
      "==================================================\n",
      "[DEBUG] Original image size: (310, 60)\n",
      "[DEBUG] Original image mode: RGB\n",
      "[DEBUG] Expected shape: (None, 200, 50, 1)\n",
      "[DEBUG] Expected channels: 1\n",
      "[DEBUG] Preprocessed image shape: (1, 200, 50, 1)\n",
      "[DEBUG] Image value range: [0.000, 0.988]\n",
      "[RESULT] Predicted CAPTCHA: ''\n",
      "[RESULT] Average confidence: 0.991\n",
      "[RESULT] Per-character confidence: ['1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '0.536', '0.998', '1.000', '1.000', '0.999', '0.997', '0.998', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000', '1.000']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "# ---------- 1. Load preprocessing components ----------\n",
    "with open(\"preprocessing_components.pkl\", \"rb\") as f:\n",
    "    preprocessing = pickle.load(f)\n",
    "\n",
    "# Extract required values\n",
    "characters = preprocessing[\"characters\"]\n",
    "max_len = preprocessing[\"max_length\"]\n",
    "img_width = preprocessing[\"img_width\"]\n",
    "img_height = preprocessing[\"img_height\"]\n",
    "char_to_num_vocab = preprocessing.get(\"char_to_num_vocab\")  # optional\n",
    "\n",
    "# Check if we need to add CTC blank token\n",
    "model_output_classes = model.output_shape[-1]\n",
    "if len(characters) < model_output_classes:\n",
    "    print(f\"[INFO] Model expects {model_output_classes} classes, but only {len(characters)} characters found.\")\n",
    "    print(\"[INFO] Adding CTC blank token...\")\n",
    "    characters = characters + [\"\"]  # Add blank token for CTC\n",
    "    \n",
    "print(f\"[INFO] Characters: {characters}\")\n",
    "print(f\"[INFO] Character count: {len(characters)}, Model output classes: {model_output_classes}\")\n",
    "print(f\"[INFO] Max length: {max_len}, Image size: {img_width}x{img_height}\")\n",
    "\n",
    "# ---------- 2. Load prediction model ----------\n",
    "model = keras.models.load_model(\"captcha_prediction_model.keras\")\n",
    "print(\"[INFO] Prediction model loaded successfully!\")\n",
    "\n",
    "# Print model input shape for debugging\n",
    "print(f\"[DEBUG] Model input shape: {model.input_shape}\")\n",
    "print(f\"[DEBUG] Model output shape: {model.output_shape}\")\n",
    "\n",
    "# ---------- 3. Preprocess input image ----------\n",
    "def preprocess_image(image_input):\n",
    "    \"\"\"\n",
    "    Preprocess image to match model's expected input format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load image\n",
    "        if isinstance(image_input, str):\n",
    "            image = Image.open(image_input)\n",
    "        else:\n",
    "            image = image_input\n",
    "        \n",
    "        print(f\"[DEBUG] Original image size: {image.size}\")\n",
    "        print(f\"[DEBUG] Original image mode: {image.mode}\")\n",
    "        \n",
    "        # Get model's expected input shape\n",
    "        expected_shape = model.input_shape\n",
    "        expected_height = expected_shape[1]\n",
    "        expected_width = expected_shape[2]\n",
    "        expected_channels = expected_shape[3] if len(expected_shape) == 4 else 1\n",
    "        \n",
    "        print(f\"[DEBUG] Expected shape: {expected_shape}\")\n",
    "        print(f\"[DEBUG] Expected channels: {expected_channels}\")\n",
    "        \n",
    "        # Resize image to expected dimensions\n",
    "        image = image.resize((expected_width, expected_height))\n",
    "        \n",
    "        # Convert to appropriate color mode\n",
    "        if expected_channels == 1:\n",
    "            # Grayscale\n",
    "            image = image.convert(\"L\")\n",
    "            image_array = np.array(image)\n",
    "            # Normalize to [0,1]\n",
    "            image_array = image_array.astype(np.float32) / 255.0\n",
    "            # Add channel dimension: (H, W) -> (H, W, 1)\n",
    "            image_array = np.expand_dims(image_array, axis=-1)\n",
    "        elif expected_channels == 3:\n",
    "            # RGB\n",
    "            image = image.convert(\"RGB\")\n",
    "            image_array = np.array(image)\n",
    "            # Normalize to [0,1]\n",
    "            image_array = image_array.astype(np.float32) / 255.0\n",
    "            # Already has 3 channels: (H, W, 3)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported number of channels: {expected_channels}\")\n",
    "        \n",
    "        # Add batch dimension: (H, W, C) -> (1, H, W, C)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        \n",
    "        print(f\"[DEBUG] Preprocessed image shape: {image_array.shape}\")\n",
    "        print(f\"[DEBUG] Image value range: [{image_array.min():.3f}, {image_array.max():.3f}]\")\n",
    "        \n",
    "        return image_array\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error in image preprocessing: {e}\")\n",
    "        raise\n",
    "\n",
    "# ---------- 4. Prediction + Decoding ----------\n",
    "def predict_captcha(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess, predict, and decode a CAPTCHA image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"[INFO] Processing image: {image_path}\")\n",
    "        \n",
    "        # Preprocess\n",
    "        processed_image = preprocess_image(image_path)\n",
    "        \n",
    "        # Predict\n",
    "        print(\"[INFO] Making prediction...\")\n",
    "        prediction = model.predict(processed_image, verbose=0)\n",
    "        \n",
    "        print(f\"[DEBUG] Prediction shape: {prediction.shape}\")\n",
    "        print(f\"[DEBUG] Prediction sample: {prediction[0][:2]}\")  # Show first 2 timesteps\n",
    "        \n",
    "        # Decode prediction (argmax per timestep)\n",
    "        predicted_indices = [np.argmax(p) for p in prediction[0]]\n",
    "        print(f\"[DEBUG] Predicted indices: {predicted_indices}\")\n",
    "        \n",
    "        # Handle CTC decoding (remove blanks and consecutive duplicates)\n",
    "        decoded_text = \"\"\n",
    "        prev_idx = -1\n",
    "        \n",
    "        for idx in predicted_indices:\n",
    "            # Skip blank tokens (usually the last index)\n",
    "            if idx == len(characters) - 1 and characters[-1] == \"\":\n",
    "                continue\n",
    "            # Skip consecutive duplicates (CTC rule)\n",
    "            if idx != prev_idx:\n",
    "                if idx < len(characters):\n",
    "                    decoded_text += characters[idx]\n",
    "                else:\n",
    "                    print(f\"[WARNING] Index {idx} out of range for characters list\")\n",
    "            prev_idx = idx\n",
    "        \n",
    "        return decoded_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error in prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "# ---------- 5. Alternative decoding methods ----------\n",
    "def predict_captcha_with_confidence(image_path, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict CAPTCHA with confidence filtering\n",
    "    \"\"\"\n",
    "    try:\n",
    "        processed_image = preprocess_image(image_path)\n",
    "        prediction = model.predict(processed_image, verbose=0)\n",
    "        \n",
    "        predicted_text = \"\"\n",
    "        confidences = []\n",
    "        prev_idx = -1\n",
    "        \n",
    "        for timestep_probs in prediction[0]:\n",
    "            max_prob = np.max(timestep_probs)\n",
    "            max_idx = np.argmax(timestep_probs)\n",
    "            \n",
    "            confidences.append(max_prob)\n",
    "            \n",
    "            # Skip blank tokens\n",
    "            if max_idx == len(characters) - 1 and characters[-1] == \"\":\n",
    "                continue\n",
    "                \n",
    "            # Skip consecutive duplicates and low confidence\n",
    "            if max_idx != prev_idx and max_prob >= confidence_threshold:\n",
    "                if max_idx < len(characters):\n",
    "                    predicted_text += characters[max_idx]\n",
    "                else:\n",
    "                    predicted_text += \"?\"\n",
    "            elif max_prob < confidence_threshold:\n",
    "                # Only add ? for non-blank, non-duplicate low confidence predictions\n",
    "                if max_idx != len(characters) - 1 and max_idx != prev_idx:\n",
    "                    predicted_text += \"?\"\n",
    "                    \n",
    "            prev_idx = max_idx\n",
    "        \n",
    "        avg_confidence = np.mean(confidences)\n",
    "        \n",
    "        return predicted_text, avg_confidence, confidences\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error in confident prediction: {e}\")\n",
    "        raise\n",
    "\n",
    "# ---------- 6. Test with error handling ----------\n",
    "def test_captcha_prediction(image_path):\n",
    "    \"\"\"\n",
    "    Test function with comprehensive error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        import os\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"[ERROR] Image file not found: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Basic prediction\n",
    "        print(\"=\"*50)\n",
    "        print(\"BASIC PREDICTION\")\n",
    "        print(\"=\"*50)\n",
    "        predicted_text = predict_captcha(image_path)\n",
    "        print(f\"[RESULT] Predicted CAPTCHA: '{predicted_text}'\")\n",
    "        \n",
    "        # Confidence-based prediction\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"CONFIDENCE-BASED PREDICTION\")\n",
    "        print(\"=\"*50)\n",
    "        pred_text, avg_conf, confidences = predict_captcha_with_confidence(image_path)\n",
    "        print(f\"[RESULT] Predicted CAPTCHA: '{pred_text}'\")\n",
    "        print(f\"[RESULT] Average confidence: {avg_conf:.3f}\")\n",
    "        print(f\"[RESULT] Per-character confidence: {[f'{c:.3f}' for c in confidences]}\")\n",
    "        \n",
    "        return predicted_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Test failed: {e}\")\n",
    "        print(\"[DEBUG] Checking model and preprocessing compatibility...\")\n",
    "        \n",
    "        # Debug model architecture\n",
    "        print(f\"[DEBUG] Model summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        return None\n",
    "\n",
    "# ---------- 7. Example usage ----------\n",
    "if __name__ == \"__main__\":\n",
    "    captcha_path = \"test_captcha.png\"  # Change to your test file\n",
    "    \n",
    "    # Test the prediction\n",
    "    result = test_captcha_prediction(captcha_path)\n",
    "    \n",
    "    if result is None:\n",
    "        print(\"\\n[INFO] Troubleshooting tips:\")\n",
    "        print(\"1. Check if the image file exists\")\n",
    "        print(\"2. Verify image dimensions match training data\")\n",
    "        print(\"3. Ensure image is in correct format (RGB/Grayscale)\")\n",
    "        print(\"4. Check if model was trained with same preprocessing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
